{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from pathlib import Path \n",
    "import sys \n",
    "import os \n",
    "import logging\n",
    "import seaborn as sns\n",
    "from decimal import Decimal, ROUND_DOWN\n",
    "import ast \n",
    "\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, GroupShuffleSplit\n",
    "from sklearn.metrics import make_scorer ,root_mean_squared_error\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GroupKFold,  cross_validate\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor \n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from skrub import TableVectorizer\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "sys.path.append('/Users/alina/Desktop/MIT/code/ADHD/MTA/helper')\n",
    "from helper import rr, prep, var_dict, audit, plot, save\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Path('/Volumes/Samsung_T5/MIT/mta').exists():\n",
    "    data_root =     '/Volumes/Samsung_T5/MIT/mta'\n",
    "    data_derived  = '/Volumes/Samsung_T5/MIT/mta/output/derived_data'\n",
    "else: \n",
    "    data_root = '/Users/alina/Desktop/MIT/code/data'\n",
    "    data_derived  = '/Users/alina/Desktop/MIT/code/data/output/derived_data'\n",
    "\n",
    "info_path = Path(data_root, \"files\")\n",
    "#os.listdir(data_derived)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## PREDICTORS ####################\n",
    "pred = pd.read_csv(Path(data_derived, 'mta_data_clean.csv')).drop(columns = 'Unnamed: 0')\n",
    "out = pd.read_csv(Path(data_derived, 'out_clean_all_raters.csv')).drop(columns = 'Unnamed: 0')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pcrc_pcrcprx_m_out pcrc_pcrcprx_m m\n",
      "RandomForestRegressor correlation_selector {'threshold': 0.8}\n",
      "50 {'n_estimators': 300, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_depth': None}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_name_save = 'results_ML_simple_CV_RF_XGB_INTIM.csv'\n",
    "file_path_save = Path(data_derived, 'ML_results', file_name_save)\n",
    "\n",
    "\n",
    "df_result  = pd.read_csv(Path(data_derived, 'ML_results', file_name_save))\n",
    "\n",
    "best_result = df_result.loc[df_result['R² Score'] == df_result['R² Score'].max(), :].drop(columns='Unnamed: 0')\n",
    "\n",
    "\n",
    "params= ast.literal_eval(best_result['Hyperparameters'].iloc[0])\n",
    "model_name = best_result['Model Name'].iloc[0]\n",
    "col_out = best_result['Outcome Variable'].iloc[0]\n",
    "rater_pred = best_result['Input Data'].iloc[0].lower()\n",
    "feature_select=  best_result['Feature Selection Method'].iloc[0]\n",
    "\n",
    "if feature_select.startswith('correlation_selector'):\n",
    "    name_part, dict_part = feature_select.split(' ', 1)\n",
    "    thr_corr = ast.literal_eval(dict_part)['threshold']\n",
    "\n",
    "thr_drop_missing = best_result['Threshold Drop Row'].iloc[0]\n",
    "original_r2 = best_result['R² Score']\n",
    "\n",
    "col_out_reduced= col_out[:-4]\n",
    "print(col_out, col_out_reduced, rater_pred)\n",
    "print(model_name, feature_select)\n",
    "print(thr_drop_missing, params)\n",
    "\n",
    "# thr_corr = params['subsample']\n",
    "# params.pop('subsample', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['src_subject_id', 'pcrc_pcrcprx_m_out', 'expect_exp1_m',\n",
      "       'expect_exp2_m', 'expect_exp3_m', 'expect_exp4_m', 'expect_exp5_m',\n",
      "       'expect_exp6_m', 'expect_exptott_m', 'snap_snap_adhd_1_m',\n",
      "       ...\n",
      "       'scid_axsima_m', 'scid_axoca1_m', 'scid_axoc1_m', 'scid_axgada_m',\n",
      "       'scid_smchk1_m', 'scid_smchk2_m', 'scid_edanoa_m', 'scid_edbula_m',\n",
      "       'scid_adjchk_m', 'trtname'],\n",
      "      dtype='object', length=280)\n",
      "Index([], dtype='object')\n",
      "Removing empty columns ..  N =  0\n",
      "Index([], dtype='object')\n",
      "(559, 280)\n",
      "Removing constant columns .. N =  0\n",
      "Index([], dtype='object')\n",
      "(559, 280)\n",
      "Removing known and raw columns..  N =  : 0\n",
      "[]\n",
      "(559, 280)\n",
      "Removing above threshold empty columns.. N =  : 0\n",
      "set()\n",
      "(559, 280)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    " ######################## extract rater pred from pred\n",
    "if rater_pred is not None:\n",
    "    col_pred = [ col for col in pred.columns if col.endswith(rater_pred)]\n",
    "    col_pred.append(\"src_subject_id\")\n",
    "    col_pred.append('trtname')\n",
    "    pred = pred[col_pred]\n",
    "    \n",
    "    \n",
    " ################ OUTCOMES ##################   \n",
    "\n",
    "out_rater = out[['src_subject_id', col_out_reduced]]\n",
    "out_rater = out_rater.rename(columns={col: f\"{col}_out\" for col in out_rater.columns if col != 'src_subject_id'})\n",
    "\n",
    "\n",
    "################ MERGE ##############\n",
    "data = pd.merge(out_rater, pred, how = 'left', on = 'src_subject_id')\n",
    "print(data.keys())\n",
    "data = audit.remove_cols(data, thr_drop_missing=thr_drop_missing) # adjust if desired, as loaded thr was 50 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To predict :  pcrc_pcrcprx_m_out\n"
     ]
    }
   ],
   "source": [
    "permute_y = True # permutation analysis \n",
    "\n",
    "y_col = col_out # extrcat single outcome to predict \n",
    "print('To predict : ', y_col)\n",
    "\n",
    "X_cols = [col for col in data.columns if col != y_col]\n",
    "data = data.dropna(subset=y_col)\n",
    "\n",
    "if permute_y:\n",
    "    y = np.random.permutation(data[y_col].values)\n",
    "else:\n",
    "    y = np.array(data[y_col])\n",
    "df_X = data[X_cols].drop(columns='src_subject_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordinal vars: ['snap_sna19_m', 'snap_sna20_m', 'snap_sna21_m', 'snap_sna22_m', 'snap_sna23_m', 'snap_sna24_m', 'snap_sna25_m', 'snap_sna26_m', 'snap_sna27_m', 'snap_sna28_m', 'snap_sna29_m', 'snap_sna30_m', 'snap_sna31_m', 'snap_sna32_m', 'snap_sna33_m', 'snap_sna34_m', 'snap_sna35_m', 'snap_sna36_m', 'snap_sna37_m', 'snap_sna38_m', 'snap_sna39_m', 'snap_snap_adhd_1_m', 'snap_snap_adhd_11_m', 'snap_snap_adhd_12_m', 'snap_snap_adhd_13_m', 'snap_snap_adhd_14_m', 'snap_snap_adhd_15_m', 'snap_snap_adhd_16_m', 'snap_snap_adhd_17_m', 'snap_snap_adhd_18_m', 'snap_snap_adhd_19_m', 'snap_snap_adhd_2_m', 'snap_snap_adhd_3_m', 'snap_snap_adhd_4_m', 'snap_snap_adhd_5_m', 'snap_snap_adhd_6_m', 'snap_snap_adhd_7_m', 'snap_snap_adhd_8_m', 'snap_snap_adhd_9_m', 'snap_snap_adhd_11_m', 'snap_snap_adhd_12_m', 'snap_snap_adhd_13_m', 'snap_snap_adhd_14_m', 'snap_snap_adhd_15_m', 'snap_snap_adhd_16_m', 'snap_snap_adhd_17_m', 'snap_snap_adhd_18_m', 'snap_snap_adhd_19_m', 'ssrs_s7t35_m', 'ssrs_s7t36_m', 'ssrs_s7t45_m', 'ssrs_s7t46_m', 'ssrs_sst15_m', 'ssrs_sst16_m', 'ssrs_sst19_m', 'ssrs_sst20_m', 'ssrs_sst37_m', 'ssrs_sst38_m', 'ssrs_sst43_m', 'ssrs_sst44_m', 'ssrs_sst47_m', 'ssrs_sst48_m', 'ssrs_s7t62_m', 'ssrs_s7t63_m', 'ssrs_s7t64_m', 'ssrs_s7t65_m', 'ssrs_s7t66_m', 'ssrs_s7t67_m', 'ssrs_s7t68_m', 'ssrs_s7t69_m', 'ssrs_s7t70_m', 'ssrs_s7t71_m', 'ssrs_s7t72_m', 'ssrs_sst65_m', 'ssrs_sst67_m', 'ssrs_sst70_m', 'ssrs_sst77_m', 'ssrs_sst78_m', 'cbcl_sports_time3_m', 'cbcl_sports_well3_m', 'cbcl_activities_time2_m', 'cbcl_activities_well2_m', 'cbcl_clubs_active1_m', 'cbcl_chores_well1_m', 'cbcl_chores_well2_m', 'pcrc_pcc21_m', 'pcrc_pcc22_m', 'pcrc_pcc23_m', 'pcrc_pcc24_m', 'pcrc_pcc25_m', 'pcrc_pcc26_m', 'pcrc_pcc27_m', 'pcrc_pcc28_m', 'pcrc_pcc29_m', 'pcrc_pcc30_m', 'pcrc_pcc31_m', 'pcrc_pcc32_m', 'pcrc_pcc33_m', 'pcrc_pcc34_m', 'pcrc_pcc35_m', 'pcrc_pcc36_m', 'pcrc_pcc37_m', 'pcrc_pcc38_m', 'pcrc_pcc39_m', 'pcrc_pcc40_m', 'expect_exp1_m', 'expect_exp2_m', 'expect_exp3_m', 'expect_exp4_m', 'expect_exp5_m', 'expect_exp6_m', 'scid_q092_phobia_life_m', 'scid_q094_ocd_life_m', 'scid_q114_an_life_m', 'scid_q116_bn_life_m', 'scid_bpl_m', 'scid_gadc_m', 'scid_somatc_m', 'scid_undfsomc_m', 'scid_hypoconc_m', 'scid_othdsml_m', 'scid_certmood_m', 'scid_certsubs_m', 'scid_certanx_m', 'scid_certsom_m', 'scid_certeat_m', 'scid_certadj_m', 'scid_grade_highed_m', 'scid_scid19_m', 'scid_mdca1_m', 'scid_mdca2_m', 'scid_mala_m', 'scid_dya_m', 'scid_psref_m', 'scid_psper_m', 'scid_psgra_m', 'scid_pssom_m', 'scid_psaud_m', 'scid_psvis_m', 'scid_pstac_m', 'scid_psnotorg_m', 'scid_sesed_m', 'scid_sucan_m', 'scid_susti_m', 'scid_suopi_m', 'scid_sucoc_m', 'scid_suhal_m', 'scid_suoth_m', 'scid_suany_m', 'scid_axpana_m', 'scid_axawpa_m', 'scid_axsoca_m', 'scid_axsima_m', 'scid_axoca1_m', 'scid_axoc1_m', 'scid_axgada_m', 'scid_edanoa_m', 'scid_edbula_m', 'scid_q018_obp_life_m', 'scid_q021_mdd_life_m', 'scid_q028_dysd_current_m', 'scid_q067_al_life_m', 'scid_q069_sha_life_m', 'scid_q071_can_life_m', 'scid_q073_stim_life_m', 'scid_q075_op_life_m', 'scid_q077_coc_life_m', 'scid_q079_hal_life_m', 'scid_q081_poly_life_m', 'scid_q083_othsub_life_m', 'scid_q085_panic_life_m', 'scid_q088_agor_life_m', 'scid_q090_social_life_m', 'cbcl_sports_time1_m', 'cbcl_sports_well1_m', 'cbcl_sports_time2_m', 'cbcl_sports_well2_m', 'cbcl_activities_time1_m', 'cbcl_activities_well1_m', 'cbcl_friends_m', 'cbcl_friends_time_m', 'cbcl_friends_time_m', 'cbcl_interp_siblings_m', 'cbcl_interp_kids_m', 'cbcl_interp_parents_m', 'cbcl_interp_alone_m', 'cbcl_school1a_m', 'cbcl_school1b_m', 'cbcl_school1c_m', 'cbcl_school1d_m', 'pcrc_pcc1_m', 'pcrc_pcc10_m', 'pcrc_pcc11_m', 'pcrc_pcc12_m', 'pcrc_pcc13_m', 'pcrc_pcc14_m', 'pcrc_pcc15_m', 'pcrc_pcc16_m', 'pcrc_pcc17_m', 'pcrc_pcc18_m', 'pcrc_pcc19_m', 'pcrc_pcc2_m', 'pcrc_pcc20_m', 'pcrc_pcc21_m', 'pcrc_pcc22_m', 'pcrc_pcc23_m', 'pcrc_pcc24_m', 'pcrc_pcc25_m', 'pcrc_pcc26_m', 'pcrc_pcc27_m', 'pcrc_pcc28_m', 'pcrc_pcc29_m', 'pcrc_pcc3_m', 'pcrc_pcc30_m', 'pcrc_pcc31_m', 'pcrc_pcc32_m', 'pcrc_pcc33_m', 'pcrc_pcc34_m', 'pcrc_pcc35_m', 'pcrc_pcc36_m', 'pcrc_pcc37_m', 'pcrc_pcc38_m', 'pcrc_pcc39_m', 'pcrc_pcc4_m', 'pcrc_pcc40_m', 'pcrc_pcc5_m', 'pcrc_pcc6_m', 'pcrc_pcc7_m', 'pcrc_pcc8_m', 'pcrc_pcc9_m', 'pcrc_pcc10_m', 'pcrc_pcc11_m', 'pcrc_pcc12_m', 'pcrc_pcc13_m', 'pcrc_pcc14_m', 'pcrc_pcc15_m', 'pcrc_pcc16_m', 'pcrc_pcc17_m', 'pcrc_pcc18_m', 'pcrc_pcc19_m', 'pcrc_pcc20_m', 'ssrs_s7t3_m', 'ssrs_s7t31_m', 'ssrs_s7t32_m', 'ssrs_s7t33_m', 'ssrs_s7t34_m', 'ssrs_s7t35_m', 'ssrs_s7t36_m', 'ssrs_s7t4_m', 'ssrs_s7t45_m', 'ssrs_s7t46_m', 'ssrs_s7t7_m', 'ssrs_s7t70_m', 'ssrs_s7t71_m', 'ssrs_s7t72_m', 'ssrs_s7t8_m', 'ssrs_s7t11_m', 'ssrs_s7t12_m', 'ssrs_s7t13_m', 'ssrs_s7t14_m', 'ssrs_s7t15_m', 'ssrs_s7t16_m', 'ssrs_s7t17_m', 'ssrs_s7t18_m', 'ssrs_s7t25_m', 'ssrs_s7t26_m', 'ssrs_s7t27_m', 'ssrs_s7t28_m', 'ssrs_s7t31_m', 'ssrs_s7t32_m', 'ssrs_s7t33_m', 'ssrs_s7t34_m', 'ssrs_s7t11_m', 'ssrs_s7t12_m', 'ssrs_s7t13_m', 'ssrs_s7t14_m', 'ssrs_s7t15_m', 'ssrs_s7t16_m', 'ssrs_s7t17_m', 'ssrs_s7t18_m', 'ssrs_s7t25_m', 'ssrs_s7t26_m', 'ssrs_s7t27_m', 'ssrs_s7t28_m', 'ssrs_s7t62_m', 'ssrs_s7t63_m', 'ssrs_s7t64_m', 'ssrs_s7t65_m', 'ssrs_s7t66_m', 'ssrs_s7t67_m', 'ssrs_s7t68_m', 'ssrs_s7t69_m']\n",
      "Numeric vars: ['snap_snainatt_m', 'snap_snahypat_m', 'snap_snaimput_m', 'snap_snaaddwt_m', 'snap_snaoddt_m', 'snap_snatotlt_m', 'snap_snahyimx_m', 'snap_snaadhdt_m', 'snap_snahit_m', 'snap_snadbdx_m', 'ssrs_sspcoopt_m', 'ssrs_sspasrtt_m', 'ssrs_sspscont_m', 'ssrs_ssptosst_m', 'ssrs_sspextt_m', 'ssrs_sspintt_m', 'ssrs_ssphypt_m', 'ssrs_ssptopbt_m', 'pcrc_pcrcposx_m', 'pcrc_pcrcprox_m', 'pcrc_pcrcaffx_m', 'pcrc_pcrcqurx_m', 'pcrc_pcrcsocx_m', 'pcrc_pcrcsimx_m', 'pcrc_pcrcprax_m', 'pcrc_pcrcdomx_m', 'pcrc_pcrcintx_m', 'pcrc_pcrcppnx_m', 'pcrc_pcrcadpx_m', 'pcrc_pcrcadcx_m', 'pcrc_pcrcprix_m', 'pcrc_pcrcnurx_m', 'pcrc_pcrcvpnx_m', 'pcrc_pcrcdecx_m', 'pcrc_pcrccomx_m', 'pcrc_pcrcgltx_m', 'pcrc_pcrcratx_m', 'pcrc_pcrcpox_m', 'pcrc_pcrcwx_m', 'pcrc_pcrcpax_m', 'pcrc_pcrcprx_m_out', 'pcrc_pcrcprx_m', 'pcrc_pcrcdwx_m', 'expect_exptott_m']\n",
      "Categorical vars: ['scid_axisidx_m', 'scid_ethnic_group_m', 'scid_das1ms_m', 'scid_pastpsy_m', 'scid_maniachk_m', 'scid_dyschk_m', 'scid_mochk1_m', 'scid_sualchk_m', 'scid_smchk1_m', 'scid_smchk2_m', 'scid_adjchk_m', 'cbcl_special_ed_m', 'cbcl_repeat_grade_m', 'cbcl_academic_m', 'trtname']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hf/frc4nxb532j7gqr3_36l6kmh0000gn/T/ipykernel_60800/2697639973.py:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  var_name = row[1]  # e.g. variable name in the spreadsheet\n",
      "/var/folders/hf/frc4nxb532j7gqr3_36l6kmh0000gn/T/ipykernel_60800/2697639973.py:9: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  var_type = row[4]  # e.g. \"ord\" / \"num\" / \"cat\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "col_names_data = list(data.columns)\n",
    "\n",
    "ord_vars, num_vars, cat_vars = [], [], []\n",
    "\n",
    "types_df = pd.read_excel(Path(data_derived, 'all_vars_description_ML.xlsx'), sheet_name='Sheet1')\n",
    "\n",
    "for _, row in types_df.iterrows():\n",
    "    var_name = row[1]  # e.g. variable name in the spreadsheet\n",
    "    var_type = row[4]  # e.g. \"ord\" / \"num\" / \"cat\"\n",
    "\n",
    "    # Collect all columns in `data` that contain `var_name`\n",
    "    var_in_data = [col for col in col_names_data if var_name in col]\n",
    "\n",
    "    if var_type == \"ord\":\n",
    "        ord_vars.append(var_in_data)\n",
    "    elif var_type == \"num\":\n",
    "        num_vars.append(var_in_data)\n",
    "    elif var_type == \"cat\":\n",
    "        cat_vars.append(var_in_data)\n",
    "\n",
    "# Example: manually add a column named 'trtname' to cat_vars\n",
    "cat_vars.append(['trtname'])\n",
    "\n",
    "# Flatten each list-of-lists into a single array\n",
    "ord_vars = np.concatenate(ord_vars)\n",
    "cat_vars = np.concatenate(cat_vars)\n",
    "num_vars = np.concatenate(num_vars)\n",
    "\n",
    "# Convert them to plain Python strings\n",
    "ord_vars = [str(col) for col in ord_vars]\n",
    "cat_vars = [str(col) for col in cat_vars]\n",
    "num_vars = [str(col) for col in num_vars]\n",
    "\n",
    "print(\"Ordinal vars:\", ord_vars)\n",
    "print(\"Numeric vars:\", num_vars)\n",
    "print(\"Categorical vars:\", cat_vars)\n",
    "\n",
    "num_vars_in = [str(col) for col in num_vars if not col.endswith(\"out\")] # name of numerical variables present in dataframe X (excludin var names in y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overlaps between numeric and ordinal: set()\n",
      "Overlaps between numeric and categorical: set()\n",
      "Overlaps between ordinal and categorical: set()\n",
      "Overlaps across numeric, ordinal and categorical: set()\n"
     ]
    }
   ],
   "source": [
    "num_set = set(num_vars_in)\n",
    "ord_set = set(ord_vars)\n",
    "cat_set = set(cat_vars)\n",
    "\n",
    "# Pairwise overlaps:\n",
    "overlap_num_ord = num_set & ord_set\n",
    "overlap_num_cat = num_set & cat_set\n",
    "overlap_ord_cat = ord_set & cat_set\n",
    "\n",
    "print(\"Overlaps between numeric and ordinal:\", overlap_num_ord)\n",
    "print(\"Overlaps between numeric and categorical:\", overlap_num_cat)\n",
    "print(\"Overlaps between ordinal and categorical:\", overlap_ord_cat)\n",
    "\n",
    "# Overlap across all three:\n",
    "overlap_all_three = num_set & ord_set & cat_set\n",
    "print(\"Overlaps across numeric, ordinal and categorical:\", overlap_all_three)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RandomForestRegressor'"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['scid_ethnic_group_m', 'scid_das1ms_m', 'trtname']\n",
      "['scid_axisidx_m', 'scid_pastpsy_m', 'scid_maniachk_m', 'scid_dyschk_m', 'scid_mochk1_m', 'scid_sualchk_m', 'scid_smchk1_m', 'scid_smchk2_m', 'scid_adjchk_m', 'cbcl_special_ed_m', 'cbcl_repeat_grade_m', 'cbcl_academic_m']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cat_vars_str, cat_vars_num, rest = [], [], []\n",
    "\n",
    "for col in cat_vars:\n",
    "    # Get the first non-null value in the column\n",
    "    val = data[col].dropna().unique()[0]\n",
    "    \n",
    "    # Check if it's a (Python or NumPy) string\n",
    "    if isinstance(val, (str, np.str_)):\n",
    "        cat_vars_str.append(str(col))  # ensure column name is a Python str\n",
    "    # Check if it's a (Python or NumPy) float\n",
    "    elif isinstance(val, (float, np.floating)):\n",
    "        cat_vars_num.append(str(col))  # ensure column name is a Python str\n",
    "    else:\n",
    "        rest.append(str(col))          # store in `rest` for debugging\n",
    "print(cat_vars_str)\n",
    "print(cat_vars_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns ending with '_m': 277\n",
      "Columns ending with '_f': 0\n",
      "Columns ending with '_c': 0\n",
      "Columns ending with '_t': 0\n"
     ]
    }
   ],
   "source": [
    "# Define the extensions to check\n",
    "extensions = ['_m', #mother \n",
    "              #'_p'# proffesionals\n",
    "              '_f', # father,\n",
    "              '_c',# child,\n",
    "              '_t'] # teacher \n",
    "\n",
    "# Count columns for each extension\n",
    "extension_counts = {ext: sum(col.endswith(ext) for col in pred.columns) for ext in extensions}\n",
    "\n",
    "for ext, count in extension_counts.items():\n",
    "    print(f\"Columns ending with '{ext}': {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_train = { 'tune_hyperparam' : False,\n",
    "          'temp_size' : 0.3, # Size of \n",
    "          'test_size' : 0.3,\n",
    "          'random_state' : 42, \n",
    "          'num_top_features': 10, # number of features to keep after featur selection, change to when it doesnt get better anymore \n",
    "          'stratify' : 'trtname',\n",
    "          'gkf_n_splits' : 5} # in balance in train teat split \n",
    "\n",
    "\n",
    "scoring = {\n",
    "    'r2': 'r2',\n",
    "    'mse': 'neg_mean_squared_error',\n",
    "    'mae': 'neg_mean_absolute_error'\n",
    "}\n",
    "\n",
    "groups = data['src_subject_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Custom Transformers\n",
    "# ----------------------------\n",
    "\n",
    "class CorrelationSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Selects features based on a correlation threshold.\n",
    "    Removes features that have a correlation higher than the specified threshold with any other feature.\n",
    "    \"\"\"\n",
    "    def __init__(self, threshold=0.8):\n",
    "        self.threshold = threshold\n",
    "        self.to_drop_ = None\n",
    "        self.features_to_keep_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            raise ValueError(\"CorrelationSelector expects input X to be a pandas DataFrame\")\n",
    "        \n",
    "        corr_matrix = X.corr().abs()\n",
    "        upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "        self.to_drop_ = [column for column in upper.columns if any(upper[column] > self.threshold)]\n",
    "        self.features_to_keep_ = [column for column in X.columns if column not in self.to_drop_]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            raise ValueError(\"CorrelationSelector expects input X to be a pandas DataFrame\")\n",
    "        return X[self.features_to_keep_]\n",
    "\n",
    "    def get_support(self, indices=False):\n",
    "        if indices:\n",
    "            return [i for i, col in enumerate(self.features_to_keep_)]\n",
    "        else:\n",
    "            return self.features_to_keep_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated column names: []\n"
     ]
    }
   ],
   "source": [
    "df_X.columns.duplicated()\n",
    "\n",
    "# To list just the duplicated columns:\n",
    "dup_cols = df_X.columns[df_X.columns.duplicated()]\n",
    "print(\"Duplicated column names:\", dup_cols.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated column names: []\n",
      "Duplicated column names: []\n"
     ]
    }
   ],
   "source": [
    "df_X.columns.duplicated()\n",
    "\n",
    "# To list just the duplicated columns:\n",
    "dup_cols = df_X.columns[df_X.columns.duplicated()]\n",
    "print(\"Duplicated column names:\", dup_cols.tolist())\n",
    "X_select = df_X[list(set(num_vars_in + ord_vars + cat_vars))]\n",
    "X_select.columns.duplicated()\n",
    "\n",
    "# To list just the duplicated columns:\n",
    "dup_cols = X_select.columns[X_select.columns.duplicated()]\n",
    "print(\"Duplicated column names:\", dup_cols.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 521\n",
      "TRAIN_VAL  (364, 278) (364,)\n",
      "TEST (157, 278) (157,)\n"
     ]
    }
   ],
   "source": [
    "# Ensure X is a DataFrame\n",
    "X = X_select.copy()\n",
    "\n",
    "# Initialize GroupShuffleSplit for initial train-test split\n",
    "gss_test = GroupShuffleSplit(n_splits=1, test_size=params_train['test_size'], random_state=params_train['random_state'])\n",
    "train_val_idx, test_idx = next(gss_test.split(X, y, groups=groups))\n",
    "\n",
    "# Split data into training-validation and test sets\n",
    "X_test, y_test, groups_test = X.iloc[test_idx], y[test_idx], groups[test_idx]\n",
    "X_train_val, y_train_val, groups_train_val = X.iloc[train_val_idx], y[train_val_idx], groups[train_val_idx]\n",
    "\n",
    "print(f\"Total samples: {X.shape[0]}\")\n",
    "print('TRAIN_VAL ', X_train_val.shape, y_train_val.shape)\n",
    "print('TEST', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataframe(X):\n",
    "    # Create a DataFrame with generic column names: f0, f1, f2, ...\n",
    "    n_cols = X.shape[1]\n",
    "    return pd.DataFrame(X, columns=[f\"f{j}\" for j in range(n_cols)])\n",
    "to_df_transformer = FunctionTransformer(func=to_dataframe, validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# param_distributions_XGB = {\n",
    "#     'regressor__n_estimators': [100, 300],  # Number of trees in the forest\n",
    "#     'regressor__max_depth': [None, 10],    # Maximum depth of the trees\n",
    "#     'regressor__max_features': ['sqrt', 'log2'],  # Number of features to consider at each split\n",
    "#     'regressor__min_samples_split': [2, 10],  # Minimum samples required to split an internal node\n",
    "#     'regressor__min_samples_leaf': [1, 4]   # Minimum samples required at a leaf node\n",
    "# }\n",
    "# param_distributions_RF = {\n",
    "#     'regressor__n_estimators': [100, 300],          # Correct prefix\n",
    "#     'regressor__max_depth': [10, None],\n",
    "#     'regressor__min_samples_split': [2, 10],\n",
    "#     'regressor__min_samples_leaf': [1, 4]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 300,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 4,\n",
       " 'max_depth': None}"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alina/opt/anaconda3/envs/abcd/lib/python3.10/site-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/Users/alina/opt/anaconda3/envs/abcd/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'regressor__n_estimators': 300, 'regressor__min_samples_split': 2, 'regressor__min_samples_leaf': 4, 'regressor__max_depth': None}\n",
      "Best Score: -0.5144263779771904\n"
     ]
    }
   ],
   "source": [
    "if model_name == 'RandomForestRegressor':\n",
    "    regress =  RandomForestRegressor(random_state=42)\n",
    "elif model_name == 'XGBRegressor':\n",
    "    regress =  XGBRegressor(random_state=42)\n",
    "\n",
    "\n",
    "num_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "ord_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('identity', FunctionTransformer(lambda x: x))\n",
    "])\n",
    "\n",
    "\n",
    "cat_to_dataframe = FunctionTransformer(\n",
    "    func=lambda X: pd.DataFrame(X, columns=cat_vars_str),\n",
    "    validate=False  # prevent extra validation that may alter the input\n",
    ")\n",
    "\n",
    "cat_str_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('to_df', cat_to_dataframe),        # conversion step added\n",
    "     ('ohe', TableVectorizer())\n",
    "])\n",
    "\n",
    "cat_num_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=-1)),\n",
    "    ('ohe', OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipe, num_vars_in),\n",
    "    ('cat_str', cat_str_pipe, cat_vars_str),\n",
    "    ('cat_num', cat_num_pipe, cat_vars_num),\n",
    "    ('ord', ord_pipe, ord_vars)\n",
    "])\n",
    "\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('to_df', to_df_transformer),\n",
    "    ('correlation_selector', CorrelationSelector(threshold=0.8)),\n",
    "    ('regressor', regress)\n",
    "])\n",
    "\n",
    "param_distributions = {\n",
    "    f'regressor__{key}':[value] for key, value in params.items()\n",
    "}\n",
    "# Define the parameter grid\n",
    "\n",
    "# Define the GroupKFold cross-validation\n",
    "cv = GroupKFold(n_splits=5)\n",
    "\n",
    "# Define the scorer\n",
    "scorer = {\n",
    "    'rmse': make_scorer(root_mean_squared_error, greater_is_better=False),\n",
    "    'mae': make_scorer(mean_absolute_error, greater_is_better=False),\n",
    "    'r2': make_scorer(r2_score)\n",
    "}\n",
    "\n",
    "# Set up the RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=10,  # Number of parameter settings to sample\n",
    "    scoring=scorer,\n",
    "    refit='rmse', \n",
    "    cv=cv,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Perform the search\n",
    "random_search.fit(X, y, groups=groups)\n",
    "\n",
    "# Print best parameters and score\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"Best Score:\", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Best Parameters:\n",
      "mean_test_rmse   -0.514426\n",
      "mean_test_mae    -0.397805\n",
      "mean_test_r2     -0.036359\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(random_search.cv_results_)\n",
    "results_df\n",
    "# Find the row corresponding to the best parameters\n",
    "best_index = random_search.best_index_\n",
    "\n",
    "# Extract metrics for the best parameters\n",
    "best_results = results_df.iloc[best_index]\n",
    "\n",
    "\n",
    "print(\"Metrics for Best Parameters:\")\n",
    "print(best_results[['mean_test_rmse', 'mean_test_mae', 'mean_test_r2']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permute_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor permutation analysis\n",
      "correlation_selector {'threshold': 0.8}\n"
     ]
    }
   ],
   "source": [
    "cross_val_strategy = str(random_search.cv)\n",
    "\n",
    "params_RF = ['n_estimators', 'criterion', 'max_depth', 'max_features']\n",
    "params_XGB = [ 'n_estimators', 'learning_rate','max_depth', 'max_leaves', 'tree_method' ]\n",
    "\n",
    "cols_res = ['Model Name', 'Cross Validation Type', 'Hyperparameters',\n",
    "       'Mean Squared Error', 'Root Mean Squared Error', 'Mean Absolute Error',\n",
    "       'R² Score', 'Outcome Variable', 'Input Data',\n",
    "       'Feature Selection Method', 'Number of Features', 'Threshold Drop Row']\n",
    "\n",
    "best_model = random_search.best_estimator_.named_steps['regressor']\n",
    "\n",
    "# Get the number of input features\n",
    "num_features = best_model.n_features_in_\n",
    "X_sample = X_train_val \n",
    "\n",
    "\n",
    "\n",
    "def truncate(value, decimals):\n",
    "    value = Decimal(value)\n",
    "    return float(value.quantize(Decimal(f\"1.{'0' * decimals}\"), rounding=ROUND_DOWN))\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(random_search.cv_results_)\n",
    "best_index = random_search.best_index_\n",
    "best_results = results_df.iloc[best_index]\n",
    "\n",
    "rmse = - truncate(best_results['mean_test_rmse'], 4)\n",
    "mse =  truncate(best_results['mean_test_rmse'] ** 2, 4)\n",
    "mae = - truncate(best_results['mean_test_mae'], 4)\n",
    "r2 = truncate(best_results['mean_test_r2'], 4)\n",
    "\n",
    "\n",
    "model_name = pipeline.named_steps['regressor'].__class__.__name__\n",
    "\n",
    "\n",
    "if model_name == 'XGBRegressor': \n",
    "    params_to_extract = params_XGB\n",
    "elif model_name == 'RandomForestRegressor':\n",
    "    params_to_extract = params_RF\n",
    "    \n",
    "if permute_y:\n",
    "\n",
    "    model_name = model_name + ' permutation analysis'\n",
    "    print(model_name)\n",
    "\n",
    "params_dict = random_search.best_params_\n",
    "params_values = str(dict(zip( [key.replace('regressor__', '') for key in random_search.best_params_.keys()], random_search.best_params_.values())))\n",
    "params_values\n",
    "\n",
    "if 'correlation_selector' in pipeline.named_steps.keys():\n",
    "    feature_select_meth ='correlation_selector {}'.format( pipeline.named_steps['correlation_selector'].get_params())\n",
    "    print(feature_select_meth)\n",
    "else: feature_select_meth = 'No feature selection'\n",
    "\n",
    "\n",
    "if  rater_pred is not None:\n",
    "    outcome_var = rater_pred.upper()\n",
    "else:\n",
    "    outcome_var = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RandomForestRegressor permutation analysis'"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Model Name', 'Cross Validation Type', 'Hyperparameters',\n",
      "       'Mean Squared Error', 'Root Mean Squared Error', 'Mean Absolute Error',\n",
      "       'R² Score', 'Outcome Variable', 'Input Data',\n",
      "       'Feature Selection Method', 'Number of Features', 'Threshold Drop Row'],\n",
      "      dtype='object')\n",
      "<class 'dict'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Cross Validation Type</th>\n",
       "      <th>Hyperparameters</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <th>R² Score</th>\n",
       "      <th>Outcome Variable</th>\n",
       "      <th>Input Data</th>\n",
       "      <th>Feature Selection Method</th>\n",
       "      <th>Number of Features</th>\n",
       "      <th>Threshold Drop Row</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>GroupKFold(n_splits=5)</td>\n",
       "      <td>{'n_estimators': 100, 'min_samples_split': 10,...</td>\n",
       "      <td>0.1725</td>\n",
       "      <td>0.4153</td>\n",
       "      <td>0.3096</td>\n",
       "      <td>0.3233</td>\n",
       "      <td>pcrc_pcrcprx_m_out</td>\n",
       "      <td>all</td>\n",
       "      <td>correlation_selector {'threshold': 0.8}</td>\n",
       "      <td>609</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>GroupKFold(n_splits=5)</td>\n",
       "      <td>{'n_estimators': 300, 'min_samples_split': 2, ...</td>\n",
       "      <td>0.1676</td>\n",
       "      <td>0.4094</td>\n",
       "      <td>0.3052</td>\n",
       "      <td>0.3432</td>\n",
       "      <td>pcrc_pcrcprx_m_out</td>\n",
       "      <td>M</td>\n",
       "      <td>correlation_selector {'threshold': 0.8}</td>\n",
       "      <td>257</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>GroupKFold(n_splits=5)</td>\n",
       "      <td>{'n_estimators': 300, 'min_samples_split': 2, ...</td>\n",
       "      <td>0.2647</td>\n",
       "      <td>0.5145</td>\n",
       "      <td>0.3984</td>\n",
       "      <td>-0.0383</td>\n",
       "      <td>pcrc_pcrcprx_m_out</td>\n",
       "      <td>F</td>\n",
       "      <td>correlation_selector {'threshold': 0.8}</td>\n",
       "      <td>187</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>GroupKFold(n_splits=5)</td>\n",
       "      <td>{'n_estimators': 300, 'min_samples_split': 2, ...</td>\n",
       "      <td>0.2608</td>\n",
       "      <td>0.5107</td>\n",
       "      <td>0.3972</td>\n",
       "      <td>-0.0294</td>\n",
       "      <td>pcrc_pcrcprx_m_out</td>\n",
       "      <td>T</td>\n",
       "      <td>correlation_selector {'threshold': 0.8}</td>\n",
       "      <td>119</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestRegressor permutation analysis</td>\n",
       "      <td>GroupKFold(n_splits=5)</td>\n",
       "      <td>{'n_estimators': 300, 'min_samples_split': 2, ...</td>\n",
       "      <td>0.2646</td>\n",
       "      <td>0.5144</td>\n",
       "      <td>0.3978</td>\n",
       "      <td>-0.0363</td>\n",
       "      <td>pcrc_pcrcprx_m_out</td>\n",
       "      <td>M</td>\n",
       "      <td>correlation_selector {'threshold': 0.8}</td>\n",
       "      <td>257</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Model Name   Cross Validation Type  \\\n",
       "0                       RandomForestRegressor  GroupKFold(n_splits=5)   \n",
       "1                       RandomForestRegressor  GroupKFold(n_splits=5)   \n",
       "2                       RandomForestRegressor  GroupKFold(n_splits=5)   \n",
       "3                       RandomForestRegressor  GroupKFold(n_splits=5)   \n",
       "4  RandomForestRegressor permutation analysis  GroupKFold(n_splits=5)   \n",
       "\n",
       "                                     Hyperparameters  Mean Squared Error  \\\n",
       "0  {'n_estimators': 100, 'min_samples_split': 10,...              0.1725   \n",
       "1  {'n_estimators': 300, 'min_samples_split': 2, ...              0.1676   \n",
       "2  {'n_estimators': 300, 'min_samples_split': 2, ...              0.2647   \n",
       "3  {'n_estimators': 300, 'min_samples_split': 2, ...              0.2608   \n",
       "4  {'n_estimators': 300, 'min_samples_split': 2, ...              0.2646   \n",
       "\n",
       "   Root Mean Squared Error  Mean Absolute Error  R² Score    Outcome Variable  \\\n",
       "0                   0.4153               0.3096    0.3233  pcrc_pcrcprx_m_out   \n",
       "1                   0.4094               0.3052    0.3432  pcrc_pcrcprx_m_out   \n",
       "2                   0.5145               0.3984   -0.0383  pcrc_pcrcprx_m_out   \n",
       "3                   0.5107               0.3972   -0.0294  pcrc_pcrcprx_m_out   \n",
       "4                   0.5144               0.3978   -0.0363  pcrc_pcrcprx_m_out   \n",
       "\n",
       "  Input Data                 Feature Selection Method  Number of Features  \\\n",
       "0        all  correlation_selector {'threshold': 0.8}                 609   \n",
       "1          M  correlation_selector {'threshold': 0.8}                 257   \n",
       "2          F  correlation_selector {'threshold': 0.8}                 187   \n",
       "3          T  correlation_selector {'threshold': 0.8}                 119   \n",
       "4          M  correlation_selector {'threshold': 0.8}                 257   \n",
       "\n",
       "   Threshold Drop Row  \n",
       "0                  50  \n",
       "1                  50  \n",
       "2                  50  \n",
       "3                  50  \n",
       "4                  50  "
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if os.path.exists(file_path_save):\n",
    "    df_result  = pd.read_csv(Path(data_derived, 'ML_results', file_name_save))\n",
    "    #df_result.columns = cols_res\n",
    "    print(df_result.columns)\n",
    "    if 'Unnamed: 0' in df_result.columns:\n",
    "        df_result = df_result.drop(columns= 'Unnamed: 0')\n",
    "else:\n",
    "    df_result = pd.DataFrame(columns= cols_res)\n",
    "\n",
    "new_row = dict(zip(cols_res, [model_name, cross_val_strategy, params_values, mse, rmse, mae, r2,  y_col,outcome_var, feature_select_meth, num_features,thr_drop_missing]))\n",
    "\n",
    "print(type(new_row))\n",
    "print(type(df_result.iloc[-1]))\n",
    "print(type( pd.Series([new_row])))\n",
    "\n",
    "try: \n",
    "    if not (df_result.iloc[-1] == pd.Series(new_row)).all() :\n",
    "        result_df = pd.concat([  df_result, pd.DataFrame([new_row])], ignore_index=True)\n",
    "        \n",
    "    else: \n",
    "        print('ROW ALREADY EXISTS')\n",
    "        result_df = df_result\n",
    "\n",
    "\n",
    "except IndexError as e:\n",
    "    if str(e) == 'single positional indexer is out-of-bounds':\n",
    "        result_df = pd.DataFrame([new_row])\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Cross Validation Type</th>\n",
       "      <th>Hyperparameters</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <th>R² Score</th>\n",
       "      <th>Outcome Variable</th>\n",
       "      <th>Input Data</th>\n",
       "      <th>Feature Selection Method</th>\n",
       "      <th>Number of Features</th>\n",
       "      <th>Threshold Drop Row</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>GroupKFold(n_splits=5)</td>\n",
       "      <td>{'n_estimators': 100, 'min_samples_split': 10,...</td>\n",
       "      <td>0.1725</td>\n",
       "      <td>0.4153</td>\n",
       "      <td>0.3096</td>\n",
       "      <td>0.3233</td>\n",
       "      <td>pcrc_pcrcprx_m_out</td>\n",
       "      <td>all</td>\n",
       "      <td>correlation_selector {'threshold': 0.8}</td>\n",
       "      <td>609</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>GroupKFold(n_splits=5)</td>\n",
       "      <td>{'n_estimators': 300, 'min_samples_split': 2, ...</td>\n",
       "      <td>0.1676</td>\n",
       "      <td>0.4094</td>\n",
       "      <td>0.3052</td>\n",
       "      <td>0.3432</td>\n",
       "      <td>pcrc_pcrcprx_m_out</td>\n",
       "      <td>M</td>\n",
       "      <td>correlation_selector {'threshold': 0.8}</td>\n",
       "      <td>257</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>GroupKFold(n_splits=5)</td>\n",
       "      <td>{'n_estimators': 300, 'min_samples_split': 2, ...</td>\n",
       "      <td>0.2647</td>\n",
       "      <td>0.5145</td>\n",
       "      <td>0.3984</td>\n",
       "      <td>-0.0383</td>\n",
       "      <td>pcrc_pcrcprx_m_out</td>\n",
       "      <td>F</td>\n",
       "      <td>correlation_selector {'threshold': 0.8}</td>\n",
       "      <td>187</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model Name   Cross Validation Type  \\\n",
       "0  RandomForestRegressor  GroupKFold(n_splits=5)   \n",
       "1  RandomForestRegressor  GroupKFold(n_splits=5)   \n",
       "2  RandomForestRegressor  GroupKFold(n_splits=5)   \n",
       "\n",
       "                                     Hyperparameters  Mean Squared Error  \\\n",
       "0  {'n_estimators': 100, 'min_samples_split': 10,...              0.1725   \n",
       "1  {'n_estimators': 300, 'min_samples_split': 2, ...              0.1676   \n",
       "2  {'n_estimators': 300, 'min_samples_split': 2, ...              0.2647   \n",
       "\n",
       "   Root Mean Squared Error  Mean Absolute Error  R² Score    Outcome Variable  \\\n",
       "0                   0.4153               0.3096    0.3233  pcrc_pcrcprx_m_out   \n",
       "1                   0.4094               0.3052    0.3432  pcrc_pcrcprx_m_out   \n",
       "2                   0.5145               0.3984   -0.0383  pcrc_pcrcprx_m_out   \n",
       "\n",
       "  Input Data                 Feature Selection Method  Number of Features  \\\n",
       "0        all  correlation_selector {'threshold': 0.8}                 609   \n",
       "1          M  correlation_selector {'threshold': 0.8}                 257   \n",
       "2          F  correlation_selector {'threshold': 0.8}                 187   \n",
       "\n",
       "   Threshold Drop Row  \n",
       "0                  50  \n",
       "1                  50  \n",
       "2                  50  "
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nrows2drop = 1\n",
    "df_result_reduced = result_df.iloc[:df_result.shape[0]-nrows2drop, :]\n",
    "df_result_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save\n",
      "full\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Cross Validation Type</th>\n",
       "      <th>Hyperparameters</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <th>R² Score</th>\n",
       "      <th>Outcome Variable</th>\n",
       "      <th>Input Data</th>\n",
       "      <th>Feature Selection Method</th>\n",
       "      <th>Number of Features</th>\n",
       "      <th>Threshold Drop Row</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>GroupKFold(n_splits=5)</td>\n",
       "      <td>{'n_estimators': 100, 'min_samples_split': 10,...</td>\n",
       "      <td>0.1725</td>\n",
       "      <td>0.4153</td>\n",
       "      <td>0.3096</td>\n",
       "      <td>0.3233</td>\n",
       "      <td>pcrc_pcrcprx_m_out</td>\n",
       "      <td>all</td>\n",
       "      <td>correlation_selector {'threshold': 0.8}</td>\n",
       "      <td>609</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>GroupKFold(n_splits=5)</td>\n",
       "      <td>{'n_estimators': 300, 'min_samples_split': 2, ...</td>\n",
       "      <td>0.1676</td>\n",
       "      <td>0.4094</td>\n",
       "      <td>0.3052</td>\n",
       "      <td>0.3432</td>\n",
       "      <td>pcrc_pcrcprx_m_out</td>\n",
       "      <td>M</td>\n",
       "      <td>correlation_selector {'threshold': 0.8}</td>\n",
       "      <td>257</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>GroupKFold(n_splits=5)</td>\n",
       "      <td>{'n_estimators': 300, 'min_samples_split': 2, ...</td>\n",
       "      <td>0.2647</td>\n",
       "      <td>0.5145</td>\n",
       "      <td>0.3984</td>\n",
       "      <td>-0.0383</td>\n",
       "      <td>pcrc_pcrcprx_m_out</td>\n",
       "      <td>F</td>\n",
       "      <td>correlation_selector {'threshold': 0.8}</td>\n",
       "      <td>187</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>GroupKFold(n_splits=5)</td>\n",
       "      <td>{'n_estimators': 300, 'min_samples_split': 2, ...</td>\n",
       "      <td>0.2608</td>\n",
       "      <td>0.5107</td>\n",
       "      <td>0.3972</td>\n",
       "      <td>-0.0294</td>\n",
       "      <td>pcrc_pcrcprx_m_out</td>\n",
       "      <td>T</td>\n",
       "      <td>correlation_selector {'threshold': 0.8}</td>\n",
       "      <td>119</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestRegressor permutation analysis</td>\n",
       "      <td>GroupKFold(n_splits=5)</td>\n",
       "      <td>{'n_estimators': 300, 'min_samples_split': 2, ...</td>\n",
       "      <td>0.2646</td>\n",
       "      <td>0.5144</td>\n",
       "      <td>0.3978</td>\n",
       "      <td>-0.0363</td>\n",
       "      <td>pcrc_pcrcprx_m_out</td>\n",
       "      <td>M</td>\n",
       "      <td>correlation_selector {'threshold': 0.8}</td>\n",
       "      <td>257</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                  Model Name  \\\n",
       "0           0                       RandomForestRegressor   \n",
       "1           1                       RandomForestRegressor   \n",
       "2           2                       RandomForestRegressor   \n",
       "3           3                       RandomForestRegressor   \n",
       "4           4  RandomForestRegressor permutation analysis   \n",
       "\n",
       "    Cross Validation Type                                    Hyperparameters  \\\n",
       "0  GroupKFold(n_splits=5)  {'n_estimators': 100, 'min_samples_split': 10,...   \n",
       "1  GroupKFold(n_splits=5)  {'n_estimators': 300, 'min_samples_split': 2, ...   \n",
       "2  GroupKFold(n_splits=5)  {'n_estimators': 300, 'min_samples_split': 2, ...   \n",
       "3  GroupKFold(n_splits=5)  {'n_estimators': 300, 'min_samples_split': 2, ...   \n",
       "4  GroupKFold(n_splits=5)  {'n_estimators': 300, 'min_samples_split': 2, ...   \n",
       "\n",
       "   Mean Squared Error  Root Mean Squared Error  Mean Absolute Error  R² Score  \\\n",
       "0              0.1725                   0.4153               0.3096    0.3233   \n",
       "1              0.1676                   0.4094               0.3052    0.3432   \n",
       "2              0.2647                   0.5145               0.3984   -0.0383   \n",
       "3              0.2608                   0.5107               0.3972   -0.0294   \n",
       "4              0.2646                   0.5144               0.3978   -0.0363   \n",
       "\n",
       "     Outcome Variable Input Data                 Feature Selection Method  \\\n",
       "0  pcrc_pcrcprx_m_out        all  correlation_selector {'threshold': 0.8}   \n",
       "1  pcrc_pcrcprx_m_out          M  correlation_selector {'threshold': 0.8}   \n",
       "2  pcrc_pcrcprx_m_out          F  correlation_selector {'threshold': 0.8}   \n",
       "3  pcrc_pcrcprx_m_out          T  correlation_selector {'threshold': 0.8}   \n",
       "4  pcrc_pcrcprx_m_out          M  correlation_selector {'threshold': 0.8}   \n",
       "\n",
       "   Number of Features  Threshold Drop Row  \n",
       "0                 609                  50  \n",
       "1                 257                  50  \n",
       "2                 187                  50  \n",
       "3                 119                  50  \n",
       "4                 257                  50  "
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save = False\n",
    "reduced = False\n",
    "if save :\n",
    "    print('save')\n",
    "    if reduced:\n",
    "        print('reduced')\n",
    "        df_result_reduced.to_csv(file_path_save)\n",
    "    else:\n",
    "        print('full')\n",
    "        result_df.to_csv(file_path_save)\n",
    "verify   = pd.read_csv(file_path_save)\n",
    "verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abcd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
