{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: debrief1401.txt\n",
      "Shape after dropna(): (434,)\n",
      "File: medse01.txt\n",
      "Shape after dropna(): (3432,)\n",
      "File: diagpsx_p201.txt\n",
      "Shape after dropna(): (2,)\n",
      "File: diagpsx_p301.txt\n",
      "Shape after dropna(): (1,)\n",
      "File: diagpsx_p401.txt\n",
      "Shape after dropna(): (1,)\n",
      "File: diagpsx_p501.txt\n",
      "Shape after dropna(): (1,)\n",
      "File: diagpsx_p601.txt\n",
      "Shape after dropna(): (1,)\n",
      "File: diagpsx_p701.txt\n",
      "Shape after dropna(): (1,)\n",
      "File: diagpsx01.txt\n",
      "Shape after dropna(): (5341,)\n",
      "Error processing file mta_pav01.txt: Error tokenizing data. C error: Expected 757 fields in line 21372, saw 1388\n",
      "\n",
      "Error processing file mta_schiz01.txt: Error tokenizing data. C error: Expected 431 fields in line 6335, saw 680\n",
      "\n",
      "Error processing file pe01.txt: Error tokenizing data. C error: Expected 340 fields in line 6333, saw 375\n",
      "\n",
      "File: schoolhx01.txt\n",
      "Shape after dropna(): (869,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the directory to search\n",
    "directory = '/Volumes/Samsung_T5/MIT/mta'\n",
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "# Loop through all files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        # Check if the file has a .txt extension\n",
    "        if filename.endswith(\".txt\")and not filename.startswith(\".\"):\n",
    "            # Construct the full file path\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            \n",
    "            try:\n",
    "                # Load the file with pandas, using tab as the delimiter\n",
    "                df = pd.read_csv(filepath, delimiter=\"\\t\")\n",
    "                \n",
    "                # Check if the 'trtname' column exists\n",
    "                if 'trtname' in df.columns:\n",
    "                    print(f\"File: {filename}\")\n",
    "                    \n",
    "                    # Drop NaN values from the 'trtname' column and print the shape\n",
    "                    column_shape = df['trtname'].dropna().shape\n",
    "                    print(f\"Shape after dropna(): {column_shape}\")\n",
    "                del df\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {filename}: {e}\")\n",
    "        \n",
    "        # Clear memory by deleting the dataframe object\n",
    "        \n",
    "\n",
    "# Perform garbage collection to ensure memory is cleared\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hf/frc4nxb532j7gqr3_36l6kmh0000gn/T/ipykernel_11290/1213211517.py:9: DtypeWarning: Columns (16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  file3 = pd.read_csv(Path(directory, file_name3), delimiter=\"\\t\",usecols=['src_subject_id', 'trtname'])\n",
      "/var/folders/hf/frc4nxb532j7gqr3_36l6kmh0000gn/T/ipykernel_11290/1213211517.py:10: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  file4 = pd.read_csv(Path(directory, file_name4), delimiter=\"\\t\",usecols=['src_subject_id', 'trtname'])\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path \n",
    "\n",
    "file_name = 'debrief1401.txt'\n",
    "file_name2 = 'medse01.txt'\n",
    "file_name3 = 'diagpsx01.txt'\n",
    "file_name4 = 'schoolhx01.txt'\n",
    "file = pd.read_csv(Path(directory, file_name), delimiter=\"\\t\" ,usecols=['src_subject_id', 'trtname'])\n",
    "file2 = pd.read_csv(Path(directory, file_name2), delimiter=\"\\t\",usecols=['src_subject_id', 'trtname'])\n",
    "file3 = pd.read_csv(Path(directory, file_name3), delimiter=\"\\t\",usecols=['src_subject_id', 'trtname'])\n",
    "file4 = pd.read_csv(Path(directory, file_name4), delimiter=\"\\t\",usecols=['src_subject_id', 'trtname'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(434, 2) (3432, 2) (14912, 2) (2879, 2)\n"
     ]
    }
   ],
   "source": [
    "print(file.shape, file2.shape, file3.shape, file4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(434,) (291,) (870,) (869,)\n",
      "['Treatment group' 'C' 'M' 'P'] ['Treatment group' 'C' 'M'] ['Treatment group' nan 'L' 'C' 'M' 'A' 'P'] ['Treatment group' 'L' 'C' 'M' 'A' 'P' nan]\n"
     ]
    }
   ],
   "source": [
    "print(file['src_subject_id'].unique().shape,file2['src_subject_id'].unique().shape,file3['src_subject_id'].unique().shape,file4['src_subject_id'].unique().shape )\n",
    "print(file['trtname'].unique(), file2['trtname'].unique(),file3['trtname'].unique(), file4['trtname'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(434, 2) (291, 2) (869, 2) (869, 2)\n",
      "['L' 'C' 'M' 'A' 'P' 'Treatment group']\n"
     ]
    }
   ],
   "source": [
    "first_entries = file.groupby('src_subject_id').first().reset_index()\n",
    "first_entries2 = file2.groupby('src_subject_id').first().reset_index()\n",
    "first_entries3 = file3.groupby('src_subject_id').first().reset_index()\n",
    "first_entries4 = file4.groupby('src_subject_id').first().reset_index()\n",
    "print(first_entries.shape, first_entries2.shape, first_entries3.shape, first_entries4.shape)\n",
    "print(first_entries3['trtname'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge1 = pd.merge(first_entries, first_entries2, how='outer', on='src_subject_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(435,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge1['src_subject_id'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge2 = pd.merge(merge1, first_entries3, how='outer', on='src_subject_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(869,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge2['src_subject_id'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['L', 'C', 'M', 'A', 'P', 'Treatment group'], dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge2.trtname.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge3 = pd.merge(merge1, first_entries4, how='outer', on='src_subject_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trtname\n",
       "L                  289\n",
       "A                  146\n",
       "C                  145\n",
       "M                  144\n",
       "P                  144\n",
       "Treatment group      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge2['trtname'].dropna()\n",
    "trtname = merge2[['src_subject_id', 'trtname']]\n",
    "trtname.value_counts(trtname['trtname'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trtname.to_csv(Path(directory, 'treatment_groups.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "869"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(merge3['trtname'].dropna()== merge2['trtname'].dropna()).sum()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abcd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
