{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "import sys\n",
    "import os\n",
    "import seaborn as sns\n",
    "import researchpy as rp\n",
    "import statsmodels.formula.api as smf\n",
    "import scipy.stats as stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#sys.path.append('/Users/alina/Desktop/MIT/code/ADHD/MTA/helper')\n",
    "from helper import rr, prep, var_dict\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '/Volumes/Samsung_T5/MIT/mta'\n",
    "derived_data = '/Volumes/Samsung_T5/MIT/mta/output/derived_data'\n",
    "#os.listdir(data_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_var = ['src_subject_id', 'interview_date', 'interview_age', 'sex', 'site', 'days_baseline']\n",
    "dtypes_baseline = { 'src_subject_id' : 'str',\n",
    "                    'interview_date': 'str' , \n",
    "                    'interview_age' : 'int64' ,\n",
    "                    'sex' : 'str', \n",
    "                    'site' : 'int64' ,\n",
    "                    'days_baseline':  'int64',\n",
    "                    'version_form': 'str'}\n",
    "version_form = ['version_form']\n",
    "\n",
    "qsts = ['snap', 'ssrs',  'pc', 'wechsler'] #masc to many missing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outcome variablles \n",
    "snap_vars = ['snainatx', 'snahypax', 'snaoddx'] #inattention_mean, hyperactie mean\n",
    "ssrs_vars = ['ssptossx', 'sspintx']# social skills mean, internalizing mean \n",
    "#masc_vars = ['masc_masctotalt']\n",
    "pc_vars = ['pcrcpax', 'pcrcprx'] # power assertion, personal closeness\n",
    "wechsler_vars = ['w1readb','w2math','w3spell' ]\n",
    "outcomes_dict  = {'snap' : snap_vars, 'ssrs' : ssrs_vars,  'pc': pc_vars, 'wechsler': wechsler_vars}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_predictors = ['days_baseline', 'site', 'trtname'] #time, site, treatment group\n",
    "\n",
    "# mediator variables\n",
    "comorb_mediators  = ['cdorodd' , 'pso', 'psoi', 'pag', 'pagi', 'pga', 'pgai' ,'psa'] #ODD/CD or anx excluding specific phobia \n",
    "services_mediators =  ['demo61'] #reciept of public assistance \n",
    "prev_med_mediators = ['hi_24'] #medication intake prior to study \n",
    "\n",
    "#moderator variables \n",
    "accept_moderator = ['d2dresp'] # initail acceptance of treatment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hf/frc4nxb532j7gqr3_36l6kmh0000gn/T/ipykernel_37481/2167685383.py:10: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  snap_ = pd.read_csv(Path(data_root, snap_file), delimiter=\"\\t\", usecols=np.concatenate((baseline_var, snap_vars, version_form)), skiprows=[1] , parse_dates=['days_baseline']).dropna(subset='days_baseline').drop_duplicates()\n",
      "/var/folders/hf/frc4nxb532j7gqr3_36l6kmh0000gn/T/ipykernel_37481/2167685383.py:11: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  ssrs_ = pd.read_csv(Path(data_root, ssrs_file), delimiter=\"\\t\", usecols=np.concatenate((baseline_var, ssrs_vars, version_form)), skiprows=[1] , parse_dates=['days_baseline']).dropna(subset='days_baseline').drop_duplicates()\n",
      "/var/folders/hf/frc4nxb532j7gqr3_36l6kmh0000gn/T/ipykernel_37481/2167685383.py:13: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pc_ = pd.read_csv(Path(data_root, parent_child_file), delimiter=\"\\t\", usecols=np.concatenate((baseline_var, pc_vars, version_form)), skiprows=[1] , parse_dates=['days_baseline']).dropna(subset='days_baseline').drop_duplicates()\n",
      "/var/folders/hf/frc4nxb532j7gqr3_36l6kmh0000gn/T/ipykernel_37481/2167685383.py:14: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  wechsler_ = pd.read_csv(Path(data_root, wechsler_file), delimiter=\"\\t\", usecols=np.concatenate((baseline_var, wechsler_vars)), skiprows=[1] , parse_dates=['days_baseline']).dropna(subset='days_baseline').drop_duplicates()\n"
     ]
    }
   ],
   "source": [
    "# load files, drop rows if missing date, drop duplicates \n",
    "\n",
    "snap_file = 'snap01.txt'\n",
    "ssrs_file = 'ssrs01.txt'\n",
    "#masc_file = 'masc_p01.txt'\n",
    "parent_child_file = 'pcrc01.txt'\n",
    "wechsler_file = 'wiat_iiip201.txt'\n",
    "treat_group = 'treatment_groups.csv'\n",
    "\n",
    "snap_ = pd.read_csv(Path(data_root, snap_file), delimiter=\"\\t\", usecols=np.concatenate((baseline_var, snap_vars, version_form)), skiprows=[1] , parse_dates=['days_baseline']).dropna(subset='days_baseline').drop_duplicates()\n",
    "ssrs_ = pd.read_csv(Path(data_root, ssrs_file), delimiter=\"\\t\", usecols=np.concatenate((baseline_var, ssrs_vars, version_form)), skiprows=[1] , parse_dates=['days_baseline']).dropna(subset='days_baseline').drop_duplicates()\n",
    "#masc_ = pd.read_csv(Path(data_root, masc_file), delimiter=\"\\t\", usecols=np.concatenate((baseline_var, masc_vars, version_form)), skiprows=[1] , parse_dates=['days_baseline']).dropna(subset='days_baseline').drop_duplicates()\n",
    "pc_ = pd.read_csv(Path(data_root, parent_child_file), delimiter=\"\\t\", usecols=np.concatenate((baseline_var, pc_vars, version_form)), skiprows=[1] , parse_dates=['days_baseline']).dropna(subset='days_baseline').drop_duplicates()\n",
    "wechsler_ = pd.read_csv(Path(data_root, wechsler_file), delimiter=\"\\t\", usecols=np.concatenate((baseline_var, wechsler_vars)), skiprows=[1] , parse_dates=['days_baseline']).dropna(subset='days_baseline').drop_duplicates()\n",
    "treat_group = pd.read_csv(Path(derived_data, treat_group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n",
      "Success\n",
      "Success\n",
      "Success\n",
      "(14540, 10) (10735, 10) (8627, 10) (4571, 10)\n"
     ]
    }
   ],
   "source": [
    "# merge with treatment group info convert colum data to appropriate dtypes \n",
    "\n",
    "snap = prep.set_baseline_dtypes(pd.merge(snap_, treat_group, how='inner', on = 'src_subject_id')).dropna()#.table with relevant snap vales, rater, and treatment group \n",
    "ssrs = prep.set_baseline_dtypes(pd.merge(ssrs_, treat_group, how='inner', on = 'src_subject_id').dropna())#.dropna() #table with relevant snap vales, rater, and treatment group \n",
    "#masc = prep.set_baseline_dtypes(pd.merge(masc_, treat_group, how='inner', on = 'src_subject_id')).dropna()#.dropna() #table with relevant snap vales, rater, and treatment group \n",
    "pc = prep.set_baseline_dtypes(pd.merge(pc_, treat_group, how='inner', on = 'src_subject_id').dropna())#.dropna() #table with relevant snap vales, rater, and treatment group \n",
    "wechsler = prep.set_baseline_dtypes(pd.merge(wechsler_, treat_group, how='inner', on = 'src_subject_id')).dropna()#.dropna() #table with relevant snap vales, rater, and treatment group \n",
    "\n",
    "print(snap_.shape, ssrs.shape, pc.shape, wechsler.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssrs.loc[ssrs['version_form'].str.startswith('Teacher'), 'version_form'] = 'Teacher'\n",
    "ssrs.loc[ssrs['version_form'].str.startswith('Parent'), 'version_form'] = 'Parent'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n",
      "Success\n",
      "Success\n",
      "Success\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hf/frc4nxb532j7gqr3_36l6kmh0000gn/T/ipykernel_37481/3879433410.py:6: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  comorb = prep.set_baseline_dtypes(pd.read_csv(Path(data_root, comorb_file), delimiter= '\\t', usecols = np.concatenate((baseline_var, comorb_mediators)), skiprows=[1] , parse_dates=['days_baseline']).dropna(subset='days_baseline').drop_duplicates())\n",
      "/var/folders/hf/frc4nxb532j7gqr3_36l6kmh0000gn/T/ipykernel_37481/3879433410.py:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  demog = prep.set_baseline_dtypes(pd.read_csv(Path(data_root, demog_file), delimiter= '\\t', usecols  =np.concatenate((baseline_var, services_mediators)), skiprows=[1] , parse_dates=['days_baseline']).dropna(subset='days_baseline').drop_duplicates())\n",
      "/var/folders/hf/frc4nxb532j7gqr3_36l6kmh0000gn/T/ipykernel_37481/3879433410.py:8: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  health_qst = prep.set_baseline_dtypes(pd.read_csv(Path(data_root, health_qst_file), delimiter= '\\t', usecols=np.concatenate((baseline_var, prev_med_mediators)), skiprows=[1] , parse_dates=['days_baseline']).dropna(subset='days_baseline').drop_duplicates())\n"
     ]
    }
   ],
   "source": [
    "comorb_file = 'diagpsx01.txt' # contains odd/cd and anx comorbid diagnoses \n",
    "demog_file = 'demgr01.txt' # contains recieot of public assistance \n",
    "health_qst_file  = 'health01.txt' # contains previous medication \n",
    "init_sat_file = 'debrief01.txt' # contains rating of initial acceptance of treatment goup\n",
    "\n",
    "comorb = prep.set_baseline_dtypes(pd.read_csv(Path(data_root, comorb_file), delimiter= '\\t', usecols = np.concatenate((baseline_var, comorb_mediators)), skiprows=[1] , parse_dates=['days_baseline']).dropna(subset='days_baseline').drop_duplicates())\n",
    "demog = prep.set_baseline_dtypes(pd.read_csv(Path(data_root, demog_file), delimiter= '\\t', usecols  =np.concatenate((baseline_var, services_mediators)), skiprows=[1] , parse_dates=['days_baseline']).dropna(subset='days_baseline').drop_duplicates())\n",
    "health_qst = prep.set_baseline_dtypes(pd.read_csv(Path(data_root, health_qst_file), delimiter= '\\t', usecols=np.concatenate((baseline_var, prev_med_mediators)), skiprows=[1] , parse_dates=['days_baseline']).dropna(subset='days_baseline').drop_duplicates())\n",
    "init_sat_file = prep.set_baseline_dtypes(pd.read_csv(Path(data_root, init_sat_file), delimiter= '\\t', usecols=np.concatenate((baseline_var,  accept_moderator)), skiprows=[1] , parse_dates=['days_baseline']).dropna(subset='days_baseline').drop_duplicates())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "snap_split_dict = prep.split_data_from_timepoints(snap)\n",
    "ssrs_split_dict = prep.split_data_from_timepoints(ssrs)\n",
    "pc_split_dict = prep.split_data_from_timepoints(pc)\n",
    "wechsler_split_dict = prep.split_data_from_timepoints(wechsler)\n",
    "data = {'snap' : snap_split_dict, 'ssrs': ssrs_split_dict, 'pc': pc_split_dict, 'wechsler': wechsler_split_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "days_baseline\n",
       "0      2880\n",
       "419      36\n",
       "196      31\n",
       "392      30\n",
       "448      30\n",
       "       ... \n",
       "49        1\n",
       "63        1\n",
       "308       1\n",
       "307       1\n",
       "327       1\n",
       "Name: count, Length: 437, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc_split_dict['14']['days_baseline'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       True\n",
       "1       True\n",
       "2       True\n",
       "3       True\n",
       "4       True\n",
       "        ... \n",
       "8665    True\n",
       "8666    True\n",
       "8667    True\n",
       "8668    True\n",
       "8669    True\n",
       "Name: days_baseline, Length: 6985, dtype: bool"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['pc']['14']['days_baseline'] == pc_split_dict['14']['days_baseline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "days_baseline\n",
       "0      2880\n",
       "419      36\n",
       "196      31\n",
       "392      30\n",
       "448      30\n",
       "       ... \n",
       "49        1\n",
       "63        1\n",
       "308       1\n",
       "307       1\n",
       "327       1\n",
       "Name: count, Length: 437, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['pc']['14']['days_baseline'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'snap': ['snainatx ~ C(trtname, Treatment(reference = \"L\")) * days_baseline * C(site)',\n",
       "  'snahypax ~ C(trtname, Treatment(reference = \"L\")) * days_baseline * C(site)',\n",
       "  'snaoddx ~ C(trtname, Treatment(reference = \"L\")) * days_baseline * C(site)'],\n",
       " 'ssrs': ['ssptossx ~ C(trtname, Treatment(reference = \"L\")) * days_baseline * C(site)',\n",
       "  'sspintx ~ C(trtname, Treatment(reference = \"L\")) * days_baseline * C(site)'],\n",
       " 'pc': ['pcrcpax ~ C(trtname, Treatment(reference = \"L\")) * days_baseline * C(site)',\n",
       "  'pcrcprx ~ C(trtname, Treatment(reference = \"L\")) * days_baseline * C(site)'],\n",
       " 'wechsler': ['w1readb ~ C(trtname, Treatment(reference = \"L\")) * days_baseline * C(site)',\n",
       "  'w2math ~ C(trtname, Treatment(reference = \"L\")) * days_baseline * C(site)',\n",
       "  'w3spell ~ C(trtname, Treatment(reference = \"L\")) * days_baseline * C(site)']}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_interact_formula = 'C(trtname, Treatment(reference = \"L\")) * days_baseline * C(site)' # reapeat with log days \n",
    "formulas =  [[' ~ '.join((var, gen_interact_formula)) for var in values] for values in outcomes_dict.values()]\n",
    "formulas_dict = dict(zip(outcomes_dict.keys(), formulas))\n",
    "formulas_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "groups = 'src_subject_id'\n",
    "alpha = 0.05\n",
    "hyps_interactions = var_dict.get_hyps_interactions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result, summ, hsmm = rr.get_RR_stats(formula, data, groups=groups, alpha= alpha)\n",
    "# rr.f_test_interactions(result, hyps_interactions, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "raters = ['Parent', 'Teacher']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_snap = [[ smf.mixedlm(formulas_dict['snap'][i], data['snap']['14'][data['snap']['14']['version_form'] == rater], groups = groups).fit() for rater in raters] for i in range(len(snap_vars))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ssrs = [[ smf.mixedlm(formulas_dict['ssrs'][i], data['ssrs']['14'][data['ssrs']['14']['version_form'] == rater], groups = groups).fit() for rater in raters] for i in range(len(ssrs_vars))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = data['pc']['14'][data['pc']['14']['version_form'] == 'Parent'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test['days_baseline'] = scaler.fit_transform(np.array(test['days_baseline']).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_pc_formula = 'pcrcpax ~ C(trtname, Treatment(reference = \"L\"))* days_baseline  '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result = smf.mixedlm(formulas_dict['pc'][0], data['pc']['14'][data['pc']['14']['version_form'] == 'Parent'], groups = groups).fit() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "# X = result.model.exog\n",
    "# vif = pd.DataFrame()\n",
    "# vif[\"VIF Factor\"] = [variance_inflation_factor(X, i) for i in range(X.shape[1])]\n",
    "# vif[\"features\"] = result.model.exog_names\n",
    "# print(vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_pc2 =  smf.mixedlm(formulas_dict['pc'][1], data['pc']['14'][data['pc']['14']['version_form'] == 'Parent'], groups = groups).fit()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_wechlser = [ smf.mixedlm(formulas_dict['wechsler'][i], data['wechsler']['14'], groups = groups).fit()  for i in range(len(wechsler_vars))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## worked for snap, ssrs, wechsler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'site': 'C(site)[T.2] = C(site)[T.3] = C(site)[T.4] = C(site)[T.5] = C(site)[T.6] = 0',\n",
       " 'site_treat': 'C(trtname, Treatment(reference=\"L\"))[T.M]:C(site)[T.2] = C(trtname, Treatment(reference=\"L\"))[T.P]:C(site)[T.2] = C(trtname, Treatment(reference=\"L\"))[T.C]:C(site)[T.2] = C(trtname, Treatment(reference=\"L\"))[T.M]:C(site)[T.3] = C(trtname, Treatment(reference=\"L\"))[T.P]:C(site)[T.3] = C(trtname, Treatment(reference=\"L\"))[T.C]:C(site)[T.3] = C(trtname, Treatment(reference=\"L\"))[T.M]:C(site)[T.4] = C(trtname, Treatment(reference=\"L\"))[T.P]:C(site)[T.4] = C(trtname, Treatment(reference=\"L\"))[T.C]:C(site)[T.4] = C(trtname, Treatment(reference=\"L\"))[T.M]:C(site)[T.5] = C(trtname, Treatment(reference=\"L\"))[T.P]:C(site)[T.5] = C(trtname, Treatment(reference=\"L\"))[T.C]:C(site)[T.5] = C(trtname, Treatment(reference=\"L\"))[T.M]:C(site)[T.6] = C(trtname, Treatment(reference=\"L\"))[T.P]:C(site)[T.6] = C(trtname, Treatment(reference=\"L\"))[T.C]:C(site)[T.6] = 0',\n",
       " 'time_treat': 'C(trtname, Treatment(reference=\"L\"))[T.M]:days_baseline = C(trtname, Treatment(reference=\"L\"))[T.P]:days_baseline  = C(trtname, Treatment(reference=\"L\"))[T.C]:days_baseline = 0'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyps_interactions = var_dict.get_hyps_interactions()\n",
    "hyps_interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snainatx   Description     Significance    F-Value       P-Value\n",
      "0        site  Not Significant   0.478532  7.925425e-01\n",
      "1  site_treat  Not Significant   0.778523  7.031027e-01\n",
      "2  time_treat    *Significant*  11.422714  1.850028e-07\n",
      "snainatx   Description     Significance    F-Value       P-Value\n",
      "0        site  Not Significant   0.285858  9.210400e-01\n",
      "1  site_treat  Not Significant   1.474889  1.054912e-01\n",
      "2  time_treat    *Significant*  16.061269  2.349415e-10\n",
      "snahypax   Description     Significance    F-Value       P-Value\n",
      "0        site  Not Significant   0.111711  9.898156e-01\n",
      "1  site_treat  Not Significant   1.643687  5.523849e-02\n",
      "2  time_treat    *Significant*  14.544289  1.998723e-09\n",
      "snahypax   Description     Significance    F-Value       P-Value\n",
      "0        site  Not Significant   1.069212  3.753642e-01\n",
      "1  site_treat  Not Significant   1.527963  8.670372e-02\n",
      "2  time_treat    *Significant*  21.565982  8.193047e-14\n",
      "snaoddx   Description     Significance   F-Value   P-Value\n",
      "0        site  Not Significant  0.398933  0.849852\n",
      "1  site_treat    *Significant*  1.754793  0.035154\n",
      "2  time_treat    *Significant*  3.415621  0.016661\n",
      "snaoddx   Description     Significance   F-Value   P-Value\n",
      "0        site  Not Significant  0.718907  0.609189\n",
      "1  site_treat  Not Significant  1.162364  0.294253\n",
      "2  time_treat    *Significant*  7.167568  0.000086\n"
     ]
    }
   ],
   "source": [
    "for i, var in enumerate(snap_vars):\n",
    "    for res in result_snap[i]:\n",
    "        print(var, rr.f_test_interactions(res, hyps_interactions, alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssptossx   Description     Significance   F-Value   P-Value\n",
      "0        site  Not Significant  0.970836  0.434083\n",
      "1  site_treat  Not Significant  0.935707  0.522976\n",
      "2  time_treat  Not Significant  0.861553  0.460281\n",
      "ssptossx   Description     Significance   F-Value   P-Value\n",
      "0        site  Not Significant  0.485249  0.787516\n",
      "1  site_treat  Not Significant  0.496734  0.943616\n",
      "2  time_treat    *Significant*  5.101886  0.001608\n",
      "sspintx   Description     Significance   F-Value   P-Value\n",
      "0        site  Not Significant  0.631833  0.675473\n",
      "1  site_treat  Not Significant  0.771165  0.711268\n",
      "2  time_treat  Not Significant  1.776329  0.149427\n",
      "sspintx   Description     Significance   F-Value   P-Value\n",
      "0        site  Not Significant  0.368243  0.870591\n",
      "1  site_treat  Not Significant  0.456635  0.961461\n",
      "2  time_treat  Not Significant  0.100833  0.959549\n"
     ]
    }
   ],
   "source": [
    "for i, var in enumerate(ssrs_vars):\n",
    "    for res in result_ssrs[i]:\n",
    "        print(var, rr.f_test_interactions(res, hyps_interactions, alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<statsmodels.regression.mixed_linear_model.MixedLMResultsWrapper object at 0x7f96fa01f9d0>\n",
      "<statsmodels.regression.mixed_linear_model.MixedLMResultsWrapper object at 0x7f96f99fb310>\n",
      "<statsmodels.regression.mixed_linear_model.MixedLMResultsWrapper object at 0x7f96f99fb640>\n"
     ]
    }
   ],
   "source": [
    "for res in result_wechlser:\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1readb   Description     Significance   F-Value   P-Value\n",
      "0        site    *Significant*  2.736320  0.018097\n",
      "1  site_treat  Not Significant  0.935301  0.523636\n",
      "2  time_treat  Not Significant  0.635075  0.592424\n",
      "w1readb   Description     Significance   F-Value   P-Value\n",
      "0        site  Not Significant  1.924660  0.087290\n",
      "1  site_treat  Not Significant  1.141942  0.312511\n",
      "2  time_treat  Not Significant  0.376829  0.769732\n",
      "w1readb   Description     Significance   F-Value   P-Value\n",
      "0        site  Not Significant  1.516170  0.181586\n",
      "1  site_treat  Not Significant  0.609549  0.869312\n",
      "2  time_treat  Not Significant  0.060611  0.980460\n",
      "w2math   Description     Significance   F-Value   P-Value\n",
      "0        site    *Significant*  2.736320  0.018097\n",
      "1  site_treat  Not Significant  0.935301  0.523636\n",
      "2  time_treat  Not Significant  0.635075  0.592424\n",
      "w2math   Description     Significance   F-Value   P-Value\n",
      "0        site  Not Significant  1.924660  0.087290\n",
      "1  site_treat  Not Significant  1.141942  0.312511\n",
      "2  time_treat  Not Significant  0.376829  0.769732\n",
      "w2math   Description     Significance   F-Value   P-Value\n",
      "0        site  Not Significant  1.516170  0.181586\n",
      "1  site_treat  Not Significant  0.609549  0.869312\n",
      "2  time_treat  Not Significant  0.060611  0.980460\n",
      "w3spell   Description     Significance   F-Value   P-Value\n",
      "0        site    *Significant*  2.736320  0.018097\n",
      "1  site_treat  Not Significant  0.935301  0.523636\n",
      "2  time_treat  Not Significant  0.635075  0.592424\n",
      "w3spell   Description     Significance   F-Value   P-Value\n",
      "0        site  Not Significant  1.924660  0.087290\n",
      "1  site_treat  Not Significant  1.141942  0.312511\n",
      "2  time_treat  Not Significant  0.376829  0.769732\n",
      "w3spell   Description     Significance   F-Value   P-Value\n",
      "0        site  Not Significant  1.516170  0.181586\n",
      "1  site_treat  Not Significant  0.609549  0.869312\n",
      "2  time_treat  Not Significant  0.060611  0.980460\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abcd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
