{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "import sys\n",
    "import os\n",
    "import seaborn as sns\n",
    "import researchpy as rp\n",
    "import statsmodels.formula.api as smf\n",
    "import scipy.stats as stats\n",
    "import ipympl\n",
    "\n",
    "#sys.path.append('/Users/alina/Desktop/MIT/code/ADHD/MTA/helper')\n",
    "from helper import rr, prep, var_dict\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Path('/Volumes/Samsung_T5/MIT/mta').exists():\n",
    "    data_root =     '/Volumes/Samsung_T5/MIT/mta'\n",
    "    data_derived = '/Volumes/Samsung_T5/MIT/mta/output/derived_data'\n",
    "else: \n",
    "    data_root = '/Users/alina/Desktop/MIT/code/data'\n",
    "    data_derived = '/Users/alina/Desktop/MIT/code/data/output/derived_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_var = ['src_subject_id', 'interview_date', 'interview_age', 'sex', 'site', 'days_baseline']\n",
    "baseline_var_short = ['src_subject_id', 'days_baseline']\n",
    "\n",
    "dtypes_baseline = { 'src_subject_id' : 'str',\n",
    "                    'interview_date': 'str' , \n",
    "                    'interview_age' : 'int64' ,\n",
    "                    'sex' : 'str', \n",
    "                    'site' : 'int64' ,\n",
    "                    'days_baseline':  'int64',\n",
    "                    'version_form': 'str'}\n",
    "\n",
    "version_form = ['version_form']\n",
    "\n",
    "qsts = ['snap', 'ssrs',  'masc', 'pc']##, 'wechsler'] #masc to many missing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cdorodd', 'anx', 'demo61', 'hi_24', 'd2dresp'], dtype='<U7')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interaction_predictors = ['days_baseline', 'site', 'trtname'] #time, site, treatment group\n",
    "\n",
    "# mediator variables\n",
    "comorb_mediators  = ['cdorodd' , 'pso', 'psoi', 'pag', 'pagi', 'pga', 'pgai' ,'psa'] #ODD/CD or anx excluding specific phobia \n",
    "services_mediators =  ['demo61'] #reciept of public assistance \n",
    "prev_med_mediators = ['hi_24'] #medication intake prior to study \n",
    "\n",
    "#moderator variables \n",
    "accept_moderator = ['d2dresp'] # initail acceptance of treatment \n",
    "raters = ['Teacher', 'Parent']\n",
    "\n",
    "med_mod_list = np.concatenate([[comorb_mediators[0]], ['anx'], services_mediators, prev_med_mediators, accept_moderator])\n",
    "med_mod_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "treat_group_file = 'treatment_groups.csv'\n",
    "treat_group = pd.read_csv(Path(data_derived, treat_group_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hf/frc4nxb532j7gqr3_36l6kmh0000gn/T/ipykernel_15303/885613445.py:6: DtypeWarning: Columns (9,16,63,64,120,122,125,126,127,128,129,130,138,140,142,144,147,150,152,159,170,172,173,174,175,180,183,184,185,186,187,188,190,192,197,198,960) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  diags1 = pd.read_csv(Path(data_root, diags1_file), delimiter = '\\t', skiprows=[1])\n",
      "/var/folders/hf/frc4nxb532j7gqr3_36l6kmh0000gn/T/ipykernel_15303/885613445.py:8: DtypeWarning: Columns (18,20,23,26,29,32,35,42,50,52,54,59,69,76,85,87,368,374,380,386,392,398) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  health_qst = pd.read_csv(Path(data_root, health_qst_file), delimiter='\\t', skiprows=[1])\n"
     ]
    }
   ],
   "source": [
    "diags1_file  = 'diagpsx01.txt' #comorbid anx and cd/odd \n",
    "demog_file = 'demgr01.txt' ##public assistance \n",
    "health_qst_file  = 'health01.txt' #prev medication \n",
    "initial_sat_file = 'debrief01.txt' #initial acceptance of treatment arm \n",
    "\n",
    "diags1 = pd.read_csv(Path(data_root, diags1_file), delimiter = '\\t', skiprows=[1])\n",
    "demog = pd.read_csv(Path(data_root, demog_file), delimiter= '\\t', skiprows=[1])\n",
    "health_qst = pd.read_csv(Path(data_root, health_qst_file), delimiter='\\t', skiprows=[1])\n",
    "init_sat = pd.read_csv(Path(data_root, initial_sat_file), delimiter='\\t', skiprows=[1])\n",
    "\n",
    "med_qsts = ['diags', 'demog', 'heath_qst', 'init_sat']\n",
    "med_qsts_dict = dict(zip(med_qsts, [diags1, demog, health_qst, init_sat]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "odd_cd_vars =[ 'cdorodd'] # CD or ODD \n",
    "anx_vars = ['pso', 'psoi', 'pag', 'pagi', 'pga', 'pgai' ,'psa', 'psai'] #poa : overanxious disorder: see if included in alaysis\n",
    "comorb_vars = np.concatenate([odd_cd_vars, anx_vars])\n",
    "\n",
    "assist_vars = ['demo61']# public assistance \n",
    "\n",
    "prev_med_vars = ['hi_24'] #prev medication \n",
    "\n",
    "accept_vars = ['d2dresp']# initial acceptance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for qst in med_qsts_dict.values():\n",
    "    print(version_form[0] in qst.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comorb = pd.read_csv(Path(data_derived, 'comorb.csv'), index_col= 0) # comorbid ODD/CD anxiety\n",
    "# prev_med = pd.read_csv(Path(data_derived, 'prev_med.csv'), index_col= 0) #'prevous stimulant medictaion exposure\n",
    "# assist = pd.read_csv(Path(data_derived, 'assist.csv'), index_col= 0) #reciept of public assistance \n",
    "# accept = pd.read_csv(Path(data_derived, 'accept.csv'), index_col= 0) #initial acceptance of treatment arm\n",
    "# medi = {'comorb': comorb, 'prev_med': prev_med, 'assist': assist, 'accept': accept}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# comorbidities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "comorb = diags1[np.concatenate([baseline_var_short,version_form, comorb_vars])]\n",
    "assist = demog[np.concatenate([baseline_var_short, assist_vars])]\n",
    "prev_med = health_qst[np.concatenate([baseline_var_short, prev_med_vars])]\n",
    "init_acc = init_sat[np.concatenate([baseline_var_short, accept_vars])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hf/frc4nxb532j7gqr3_36l6kmh0000gn/T/ipykernel_15303/3060119594.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  comorb['anx'] = pd.NA\n"
     ]
    }
   ],
   "source": [
    "comorb['anx'] = pd.NA\n",
    "anx_vars = [ 'pso', 'psoi', 'pag', 'pagi', 'pga', 'pgai', 'psa', 'psai']\n",
    "mask = (comorb[anx_vars].fillna(0) != 0).any(axis=1)  # Extract if any anxiety disdoers, comorb anx = True \n",
    "comorb.loc[mask, 'anx'] = 1\n",
    "mask = (comorb[anx_vars] == 0).all(axis=1)  # If none of the disorder, Comorb anx = False, else NaN \n",
    "comorb.loc[mask, 'anx'] = 0\n",
    "comorb = comorb.drop(columns=anx_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split data from timepoints so that only 1 diagnosis per timepoint per subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "867"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(comorb['days_baseline'] < 150).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timepoints = [50, 213, 578, 912] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_unique_subjects(df, lower_bound_time=None, select='min'):\n",
    "    if lower_bound_time is not None:\n",
    "        df = df.loc[df['days_baseline'] > lower_bound_time].copy()\n",
    "    \n",
    "    # Fix for the error - Using value_counts and filtering properly\n",
    "    duplicates = df['src_subject_id'].value_counts()[df['src_subject_id'].value_counts() > 1].index\n",
    "    duplicates_df = df[df['src_subject_id'].isin(duplicates)]\n",
    "\n",
    "    if select == 'min':\n",
    "        idx_to_keep = duplicates_df.groupby('src_subject_id')['days_baseline'].idxmin()\n",
    "    elif select == 'max':\n",
    "        idx_to_keep = duplicates_df.groupby('src_subject_id')['days_baseline'].idxmax()\n",
    "    else:\n",
    "        raise ValueError('Please specify how to select unique subjects')\n",
    "    \n",
    "    return df.loc[df.index.difference(duplicates_df.index).union(idx_to_keep)]\n",
    "\n",
    "def get_unique_subjects_split(df, timepoints_unique = None, select='min', timepoints_split = None):\n",
    "    df_split = prep.split_data_from_timepoints(df, timepoints_split)\n",
    "    \n",
    "    if timepoints_unique is not None:\n",
    "        df_split_unique = [\n",
    "            find_unique_subjects(df_timepoint, time, select) for df_timepoint, time in zip(df_split.values(), timepoints_unique)\n",
    "        ]\n",
    "    else:\n",
    "        df_split_unique = [\n",
    "            find_unique_subjects(df_timepoint, None, select) for df_timepoint in df_split.values()\n",
    "        ]\n",
    "    \n",
    "    for df_ in df_split_unique:\n",
    "        if (df_['src_subject_id'].value_counts() > 1).sum() == 0:\n",
    "            print('Success')\n",
    "        else:\n",
    "            print('Found {} duplicates remaining.'.format((df_['src_subject_id'].value_counts() > 1).sum()))\n",
    "    \n",
    "    return df_split_unique\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50, 213, 578, 912]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "comorb_split = prep.split_data_from_timepoints(comorb)\n",
    "comorb_split_unique = [ find_unique_subjects(comorb_timepoint, None, select='min') for comorb_timepoint, time in zip(comorb_split.values(), timepoints) ]\n",
    "for df in comorb_split_unique:\n",
    "    print((df['src_subject_id'].value_counts() > 1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n",
      "Success\n",
      "Success\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "comorb_split_unique = get_unique_subjects_split(comorb, None, select='min', timepoints_split=[213, 578, 912, 1095])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(867, 5)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comorb_split_unique[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previous medication "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n",
      "Success\n",
      "Success\n",
      "Success\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alina/Desktop/MIT/code/ADHD/MTA/helper/prep.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  except ValueError as e :\n"
     ]
    }
   ],
   "source": [
    "prev_med_split_unique = get_unique_subjects_split(prev_med,  None, select='min', timepoints_split=[213, 578, 912, 1095])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_subject_id</th>\n",
       "      <th>days_baseline</th>\n",
       "      <th>hi_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P1001</td>\n",
       "      <td>3029</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P1001</td>\n",
       "      <td>3836</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P1001</td>\n",
       "      <td>4786</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P1001</td>\n",
       "      <td>5297</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P1002</td>\n",
       "      <td>4942</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2822</th>\n",
       "      <td>P1867</td>\n",
       "      <td>4919</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2823</th>\n",
       "      <td>P1868</td>\n",
       "      <td>3114</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2824</th>\n",
       "      <td>P1868</td>\n",
       "      <td>3828</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2825</th>\n",
       "      <td>P1868</td>\n",
       "      <td>4627</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2826</th>\n",
       "      <td>P1868</td>\n",
       "      <td>5251</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2827 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     src_subject_id  days_baseline  hi_24\n",
       "0             P1001           3029    NaN\n",
       "1             P1001           3836    1.0\n",
       "2             P1001           4786    1.0\n",
       "3             P1001           5297    1.0\n",
       "4             P1002           4942    2.0\n",
       "...             ...            ...    ...\n",
       "2822          P1867           4919    1.0\n",
       "2823          P1868           3114    NaN\n",
       "2824          P1868           3828    1.0\n",
       "2825          P1868           4627    1.0\n",
       "2826          P1868           5251    1.0\n",
       "\n",
       "[2827 rows x 3 columns]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "days_baseline\n",
       "3734    8\n",
       "3760    6\n",
       "3821    6\n",
       "3653    6\n",
       "3711    6\n",
       "       ..\n",
       "4687    1\n",
       "3935    1\n",
       "5578    1\n",
       "4864    1\n",
       "5251    1\n",
       "Name: count, Length: 1812, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_med['days_baseline'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alina/Desktop/MIT/code/ADHD/MTA/helper/prep.py:91: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  for i, col in zip(range(df.shape[1]), df.columns):\n"
     ]
    }
   ],
   "source": [
    "prev_med_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_subject_id</th>\n",
       "      <th>days_baseline</th>\n",
       "      <th>hi_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P1001</td>\n",
       "      <td>3029</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P1002</td>\n",
       "      <td>4942</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>P1003</td>\n",
       "      <td>3928</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>P1004</td>\n",
       "      <td>3646</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>P1005</td>\n",
       "      <td>5180</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2808</th>\n",
       "      <td>P1864</td>\n",
       "      <td>3019</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2812</th>\n",
       "      <td>P1865</td>\n",
       "      <td>2999</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2815</th>\n",
       "      <td>P1866</td>\n",
       "      <td>2988</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2819</th>\n",
       "      <td>P1867</td>\n",
       "      <td>2616</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2823</th>\n",
       "      <td>P1868</td>\n",
       "      <td>3114</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>762 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     src_subject_id  days_baseline  hi_24\n",
       "0             P1001           3029    NaN\n",
       "4             P1002           4942    2.0\n",
       "7             P1003           3928    NaN\n",
       "11            P1004           3646    NaN\n",
       "15            P1005           5180    2.0\n",
       "...             ...            ...    ...\n",
       "2808          P1864           3019    NaN\n",
       "2812          P1865           2999    NaN\n",
       "2815          P1866           2988    NaN\n",
       "2819          P1867           2616    NaN\n",
       "2823          P1868           3114    NaN\n",
       "\n",
       "[762 rows x 3 columns]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_med_unique = find_unique_subjects(prev_med)\n",
    "prev_med_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### recipet of public assistance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_subject_id</th>\n",
       "      <th>days_baseline</th>\n",
       "      <th>demo61</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P1001</td>\n",
       "      <td>1612</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P1003</td>\n",
       "      <td>2647</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>P1004</td>\n",
       "      <td>2633</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>P1006</td>\n",
       "      <td>2560</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>P1007</td>\n",
       "      <td>2852</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3855</th>\n",
       "      <td>P1780</td>\n",
       "      <td>4108</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3912</th>\n",
       "      <td>P1804</td>\n",
       "      <td>3901</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3946</th>\n",
       "      <td>P1818</td>\n",
       "      <td>4530</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3963</th>\n",
       "      <td>P1826</td>\n",
       "      <td>4858</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4045</th>\n",
       "      <td>P1858</td>\n",
       "      <td>4050</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>798 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     src_subject_id  days_baseline  demo61\n",
       "0             P1001           1612     2.0\n",
       "3             P1003           2647     2.0\n",
       "6             P1004           2633     2.0\n",
       "9             P1006           2560     2.0\n",
       "12            P1007           2852     2.0\n",
       "...             ...            ...     ...\n",
       "3855          P1780           4108     NaN\n",
       "3912          P1804           3901     NaN\n",
       "3946          P1818           4530     NaN\n",
       "3963          P1826           4858     NaN\n",
       "4045          P1858           4050     NaN\n",
       "\n",
       "[798 rows x 3 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assist_unique = find_unique_subjects(assist)\n",
    "assist_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial acceptance is already unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "comorb_b = comorb_split_unique[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(867, 5) (762, 3) (798, 3) (579, 3)\n"
     ]
    }
   ],
   "source": [
    "print(comorb_b.shape, prev_med_unique.shape, assist_unique.shape, init_acc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop days baseline and version form for merging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "comorb_b = comorb_b.drop(columns='version_form')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_clean = [df.drop(columns='days_baseline') for df in [comorb_b, prev_med_unique, assist_unique, init_acc]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[     src_subject_id  cdorodd anx\n",
       " 6663          P1001      0.0   0\n",
       " 6665          P1002      NaN   0\n",
       " 6668          P1003      1.0   1\n",
       " 6672          P1004      0.0   1\n",
       " 6676          P1005      1.0   0\n",
       " ...             ...      ...  ..\n",
       " 9323          P1864      0.0   0\n",
       " 9325          P1865      0.0   0\n",
       " 9327          P1866      0.0   0\n",
       " 9329          P1867      0.0   0\n",
       " 9331          P1868      0.0   1\n",
       " \n",
       " [867 rows x 3 columns],\n",
       "      src_subject_id  hi_24\n",
       " 0             P1001    NaN\n",
       " 4             P1002    2.0\n",
       " 7             P1003    NaN\n",
       " 11            P1004    NaN\n",
       " 15            P1005    2.0\n",
       " ...             ...    ...\n",
       " 2808          P1864    NaN\n",
       " 2812          P1865    NaN\n",
       " 2815          P1866    NaN\n",
       " 2819          P1867    NaN\n",
       " 2823          P1868    NaN\n",
       " \n",
       " [762 rows x 2 columns],\n",
       "      src_subject_id  demo61\n",
       " 0             P1001     2.0\n",
       " 3             P1003     2.0\n",
       " 6             P1004     2.0\n",
       " 9             P1006     2.0\n",
       " 12            P1007     2.0\n",
       " ...             ...     ...\n",
       " 3855          P1780     NaN\n",
       " 3912          P1804     NaN\n",
       " 3946          P1818     NaN\n",
       " 3963          P1826     NaN\n",
       " 4045          P1858     NaN\n",
       " \n",
       " [798 rows x 2 columns],\n",
       "     src_subject_id  d2dresp\n",
       " 0            P1002      NaN\n",
       " 1            P1003      NaN\n",
       " 2            P1004      NaN\n",
       " 3            P1005      NaN\n",
       " 4            P1006      NaN\n",
       " ..             ...      ...\n",
       " 574          P1830      6.0\n",
       " 575          P1837      4.0\n",
       " 576          P1839      5.0\n",
       " 577          P1842      3.0\n",
       " 578          P1844      3.0\n",
       " \n",
       " [579 rows x 2 columns]]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge with data for the regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_var = ['src_subject_id', 'interview_date', 'interview_age', 'sex', 'site', 'days_baseline']\n",
    "dtypes_baseline = { 'src_subject_id' : 'str',\n",
    "                    'interview_date': 'str' , \n",
    "                    'interview_age' : 'int64' ,\n",
    "                    'sex' : 'str', \n",
    "                    'site' : 'int64' ,\n",
    "                    'days_baseline':  'int64',\n",
    "                    'version_form': 'str'}\n",
    "\n",
    "version_form = ['version_form']\n",
    "\n",
    "qsts = ['snap', 'ssrs',  'masc', 'pc']##, 'wechsler'] #masc to many missing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "snap_file = 'snap01.txt'\n",
    "ssrs_file = 'ssrs01.txt'\n",
    "masc_file = 'masc_p01.txt'\n",
    "parent_child_file = 'pcrc01.txt'\n",
    "wechsler_file = 'wiat_iiip201.txt'\n",
    "treat_group_file = 'treatment_groups.csv'\n",
    "#outcome variablles \n",
    "snap_vars = ['snainatx', 'snahypax', 'snaoddx'] #inattention_mean, hyperactie mean\n",
    "ssrs_vars = ['sspintx', 'ssptossx']# social skills mean, internalizing mean \n",
    "masc_vars = ['masc_masctotalt']\n",
    "pc_vars = ['pcrcpax', 'pcrcprx'] # power assertion, personal closeness\n",
    "#wechsler_vars = ['w1readb','w2math','w3spell' ]\n",
    "outcomes_dict  = {'snap' : snap_vars, 'ssrs' : ssrs_vars, 'masc':masc_vars ,'pc': pc_vars} #, 'wechsler': wechsler_vars}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n",
      "Success\n",
      "Success\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "treat_group = pd.read_csv(Path(data_derived, treat_group_file))\n",
    "\n",
    "snap = prep.get_data(Path(data_root, snap_file), columns= [baseline_var, snap_vars, version_form], treat_group= treat_group, set_dtypes= True, version_form= True, split_timepoints= True)\n",
    "ssrs = prep.get_data(Path(data_root, ssrs_file), columns= [baseline_var, ssrs_vars, version_form], treat_group= treat_group, set_dtypes= True, version_form= True, split_timepoints= True)\n",
    "masc = prep.get_data(Path(data_root, masc_file), columns= [baseline_var, masc_vars], treat_group= treat_group, set_dtypes= True, version_form= False, split_timepoints= True)\n",
    "\n",
    "pc = prep.get_data(Path(data_root, parent_child_file), columns= [baseline_var, pc_vars], treat_group= treat_group, set_dtypes= True, version_form= False, split_timepoints= True)\n",
    "#wechsler = prep.get_data(Path(data_root, wechsler_file), columns= [baseline_var, wechsler_vars], set_dtypes= True, version_form= False, split_timepoints= True)\n",
    "data_dict = dict(zip(qsts, [snap, ssrs, masc, pc]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_14_months = [data['14'] for data in data_dict.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [pd.merge(data, dfs_clean[0], on= 'src_subject_id') for data in data_14_months]\n",
    "test2 = [pd.merge(data, dfs_clean[1], on= 'src_subject_id') for data in test]\n",
    "test3 = [pd.merge(data, dfs_clean[2], on= 'src_subject_id') for data in test2]\n",
    "test4 = [pd.merge(data, dfs_clean[3], on= 'src_subject_id') for data in test3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test4[0].to_csv(Path(data_derived, 'snap_14_and_mediators.csv'))\n",
    "# test4[1].to_csv(Path(data_derived, 'ssrs_14_and_mediators.csv'))\n",
    "# test4[2].to_csv(Path(data_derived, 'masc_14_and_mediators.csv'))\n",
    "# test4[3].to_csv(Path(data_derived, 'pc_14_and_mediators.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abcd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
